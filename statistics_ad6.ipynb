{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "                                                   Statistics Advance-6",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n    the validity of the results.",
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": "Analysis of Variance (ANOVA) is a statistical technique used to compare means between two or more groups to \n          determine if there are statistically significant differences among them. To use ANOVA effectively,\n          certain assumptions must be met. Violations of these assumptions can impact the validity of the results.\n          \n          \n        1.Independence: The observations within each group should be independent of each other.\n            This means that the value of one observation should not be influenced by the value of \n            another observation in the same group. Violations of independence can occur in various ways,\n            such as when measurements are taken from the same subject multiple times (repeated measures) without proper accounting.\n            \n        >Example of Violation: In a drug trial, the same group of patients is measured for their blood pressure at multiple time points.\n                The measurements within the same patient may not be independent, violating the independence assumption.\n                \n                \n        2.Normality: The data within each group should follow a normal distribution.\n            This means that the data points should be symmetrically distributed around the mean, \n             with most data points clustering around the mean and fewer data points in the tails of the distribution. \n              Violations of normality can lead to incorrect conclusions.\n\n       Example of Violation: If the data within one group are strongly skewed or have extreme outliers,\n                    it can violate the normality assumption. For instance, in a study of exam scores,\n                    if one group's scores are heavily skewed to the right, ANOVA assumptions may not hold. \n                    \n                    \n        3.Homogeneity of Variance (Homoscedasticity): The variance of the data in each group should be approximately equal.\n             In other words, the spread of data points around the group means should be similar across all groups. Violations \n             of homogeneity of variance can lead to inaccurate p-values and can affect the reliability of ANOVA results.\n\n         Example of Violation: If you are comparing the weights of three different breeds of dogs, \n                 and one breed has a much larger variance in weights than the others, \n                 it violates the homogeneity of variance assumption.\n                 \n                 \n                 \n        4.Independence of Errors: The residuals (the differences between the observed values and the predicted values)\n             should be independent of each other and have constant variance across all groups.\n             Violations of this assumption can lead to incorrect estimates of the standard error\n             and can affect the validity of the p-values.\n\n           Example of Violation: In a longitudinal study tracking the performance of students over time,\n           if the residuals from the ANOVA model are correlated over time or exhibit patterns, \n           it violates the independence of errors assumption\n           \n           \n        5.Equal Sample Sizes (for one-way ANOVA): In a one-way ANOVA (comparing means across multiple groups),\n                  it is assumed that the sample sizes in each group are equal or at least roughly equal.\n                  When sample sizes are significantly different, it can affect the power of the analysis and make it less robust.\n\n                 Example of Violation: In a one-way ANOVA comparing the performance of three different schools,\n                     if one school has a much larger sample size than the others, it may affect the validity of the results. \n                     \n                     \n        ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "Q2. What are the three types of ANOVA, and in what situations would each be used?",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "1.One-Way ANOVA\n         >.Use Case;\n                   Use Case: One-way ANOVA is used when you have one categorical independent variable\n                   (factor) with more than two levels (groups), and you want to determine if there are \n                   statistically significant differences in the means of a continuous dependent variable among these groups.\n                   \n          >Example: You want to compare the average test scores of students from three different schools\n                    (School A, School B, and School C) to see if there is a significant difference in performance.\n                    \n2.Two-Way ANOVA:\n                >Use Case: Two-way ANOVA is used when you have two categorical independent variables (factors),\n                and you want to determine their individual and interactive effects on a continuous dependent variable.\n                \n                \n                >Example: You want to study the effects of both gender (Male/Female) and treatment (Treatment A/Treatment B)\n                    on the recovery time of patients. Two-way ANOVA helps you assess whether gender, treatment, \n                    or their interaction significantly influences recovery time.\n                    \n3.Repeated Measures ANOVA:\n\n                     Use Case: Repeated Measures ANOVA is used when you have a single group of subjects (or items)\n                     that are measured at multiple time points or under different conditions, and you want to determine\n                     if there are statistically significant differences across these repeated measurements or conditions.\n                     \n                     \n              Example: You are conducting a study to measure the blood pressure of the same group of individuals \n                     before and after receiving three different treatments (Treatment X, Treatment Y, and Treatment Z).\n                     Repeated Measures ANOVA helps assess if the treatments have a significant effect on blood pressure over time. \n                     \n                     \n                     ",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "The partitioning of variance in Analysis of Variance (ANOVA) is a fundamental concept that helps in understanding \n   how the total variability in a dataset is broken down into different components, which can be attributed to different\n   sources or factors. This partitioning is essential in ANOVA because it allows researchers to assess the contributions\n   of various factors to the observed variability in the data\n   \n   1.Total Variance (Total Sum of Squares - SST):-This is the total variability observed in the data. It represents the sum of squared\n                         differences between each data point and the overall mean of all data points. Mathematically\n\n              SST = Σ(Yij - Grand Mean)^2\n\n            Where:\n\n              >Yij is an individual data point.\n               >Grand Mean is the mean of all data points.\n               \n               \n   2.Between-Group Variance (Between-Group Sum of Squares - SSB):This component measures the variability between the group means.\n             It represents the sum of squared differences between each group mean and the overall mean. Mathematically\n             \n\n             SSB = Σ(ni * (Group Mean_i - Grand Mean)^2)\n             \n           Where:\n\n             ni is the sample size of the i-th group.\n             Group Mean_i is the mean of the i-th group.\n             Grand Mean is the mean of all data points  \n             \n   3.Within-Group Variance (Within-Group Sum of Squares - SSW): This component measures the variability within each group. \n          It represents the sum of squared differences between individual data points and their respective group means.\n          \n\n        SSW = ΣΣ(Yij - Group Mean_i)^2\n\n        Where:\n\n           >Yij is an individual data point in the i-th group.\n           >Group Mean_i is the mean of the i-th group.\n           \n       1.Hypothesis Testing: ANOVA helps determine whether there are statistically significant differences between \n            groups or conditions. By partitioning the variance, ANOVA provides a way to test whether the between-group \n            variability (SSB) is significantly greater than the within-group variability (SSW).\n            \n            \n\n        2.Effect Size: It allows researchers to assess the magnitude of the effect of the independent variable\n               (group or condition) on the dependent variable. The ratio of between-group variance to within-group variance,\n                known as the F-statistic, provides a measure of effect size.   \n                \n        3.Understanding Sources of Variation: Researchers can gain insights into the sources of variation in the data.\n        \n        \n                For example, ANOVA can help identify which group or condition is responsible for the observed differences.\n\n        4.Model Interpretation: It aids in interpreting and explaining the results of the analysis. Researchers can discuss\n                the proportion of variability attributable to different factors.  \n                \n                ",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\nsum of squares (SSR) in a one-way ANOVA using Python?",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nfrom scipy import stats\n\n\ngroup1 = np.array([68, 72, 75, 71, 73])\ngroup2 = np.array([64, 66, 68, 65, 67])\ngroup3 = np.array([75, 78, 82, 79, 80])\n\n\nall_data = np.concatenate([group1, group2, group3])\n\n\ngrand_mean = np.mean(all_data)\n\n\nsst = np.sum((all_data - grand_mean) ** 2)\n\nmean_group1 = np.mean(group1)\nmean_group2 = np.mean(group2)\nmean_group3 = np.mean(group3)\n\n\nsse = np.sum((group1 - mean_group1) ** 2) + np.sum((group2 - mean_group2) ** 2) + np.sum((group3 - mean_group3) ** 2)\n\n\ndf_sse = len(all_data) - 3  # Three groups, so 3 degrees of freedom\n\n\nssr = sst - sse\n\n\ndf_ssr = 3 - 1  # Three groups minus one\n\n\nmse = sse / df_sse\nmsr = ssr / df_ssr\n\n\nf_statistic = msr / mse\n\np_value = 1 - stats.f.cdf(f_statistic, df_ssr, df_sse)\n\nprint(f\"SST (Total Sum of Squares): {sst}\")\nprint(f\"SSE (Explained Sum of Squares): {sse}\")\nprint(f\"SSR (Residual Sum of Squares): {ssr}\")\nprint(f\"F-statistic: {f_statistic}\")\nprint(f\"P-value: {p_value}\")\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "text": "SST (Total Sum of Squares): 474.40000000000003\nSSE (Explained Sum of Squares): 63.60000000000001\nSSR (Residual Sum of Squares): 410.8\nF-statistic: 38.75471698113207\nP-value: 5.8059676509847336e-06\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\n\ndependent_variable = np.array([80, 90, 85, 75, 83, 94, 98, 79, 71, 80])\nindependent_variable_1 = np.array(['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'C'])\nindependent_variable_2 = np.array(['T1', 'T1', 'T2', 'T2', 'T3', 'T3', 'T1', 'T1', 'T2', 'T2'])\n\nimport pandas as pd\ndf = pd.DataFrame({'Dependent_Variable': dependent_variable,\n                   'Independent_Variable_1': independent_variable_1,\n                   'Independent_Variable_2': independent_variable_2})\n\nmodel = ols('Dependent_Variable ~ C(Independent_Variable_1) * C(Independent_Variable_2)', data=df).fit()\n\n\nanova_table = sm.stats.anova_lm(model, typ=2)\n\nmain_effect_1 = anova_table.loc['C(Independent_Variable_1)', 'F']\nmain_effect_2 = anova_table.loc['C(Independent_Variable_2)', 'F']\ninteraction_effect = anova_table.loc['C(Independent_Variable_1):C(Independent_Variable_2)', 'F']\n\nprint('Main effect 1:', main_effect_1)\nprint('Main effect 2:', main_effect_2)\nprint('Interaction effect:', interaction_effect)\n\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 10,
      "outputs": [
        {
          "name": "stderr",
          "text": "/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n  warnings.warn('covariance of constraints does not have full '\n/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n  warnings.warn('covariance of constraints does not have full '\n/lib/python3.11/site-packages/statsmodels/base/model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 4, but rank is 3\n  warnings.warn('covariance of constraints does not have full '\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Main effect 1: 0.02427637721755136\nMain effect 2: 2.5029088558500394\nInteraction effect: 0.3401565754506945\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\nWhat can you conclude about the differences between the groups, and how would you interpret these\nresults?",
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": "In a one-way ANOVA, the F-statistic and the associated p-value are used to determine whether  \n       there are statistically significant differences in the means of the groups being compared.\n    \n1.F-Statistic: The F-statistic in your analysis is 5.23. This value represents the ratio of\n      the between-group variability to the within-group variability. In simpler terms,\n      it measures how much the means of the groups differ relative to the variability within each grou\n        \n        \n2.P-value: The p-value associated with the F-statistic is 0.02. This p-value indicates the probability\n     of observing such an extreme F-statistic by random chance alone, assuming that there are no \n      real differences between the groups.\n        \n\n        >Null Hypothesis (H0): The null hypothesis in a one-way ANOVA states that there are no\n        significant differences in the means of the groups being compared. In other words,\n        all group means are equal.\n        \n        >Alternative Hypothesis (Ha): The alternative hypothesis, which you would consider\n            if the p-value is small (typically less than your chosen significance level, \n            often denoted as α), suggests that there are significant differences in the means\n            of at least some of the groups.\n            \n\n            \nSince the p-value (0.02) is less than the typical significance level of 0.05 (or 5%),\n    you would reject the null hypothesis (H0) in favor of the alternative hypothesis (Ha).\n    This means that there is evidence to suggest that there are significant differences\n    in the means of at least some of the groups.\n    \n    ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\nconsequences of using different methods to handle missing data?",
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": "1..Listwise Deletion (Complete Case Analysis):\n\n         >Method: Exclude cases with missing data on any of the variables used in the analysis.\n         >Consequences:\n                \n         >Pros: Simple to implement.\n        \n          >ons: Reduces the sample size, potentially leading to a loss of statistical power and biased estimates \n            if the missing data are not missing completely at random (MCAR). It may also introduce selection bias\n            if the missingness is related to specific participant characteristics or conditions. \n            \n2.Pairwise Deletion (Available Case Analysis):  \n             \n        >Method: Include all cases for each specific comparison (pair) where data are available.\n        >Consequences\n        Pros: Retains more data, allowing for more comparisons.\n        \n     Cons: Can lead to different sample sizes for different comparisons, making it difficult to directly compare\n       results across comparisons. Like listwise deletion, it may lead to biased estimates if data are not MCAR.\n        \n      Pros: Retains more data, allowing for more comparisons.\n    \n     Cons: Can lead to different sample sizes for different comparisons, making it difficult to directly compare \n           results across comparisons. Like listwise deletion, it may lead to biased estimates if data are not MCAR.\n            \n            \n        Imputation:    \n        Method: Impute missing values with estimated values based on observed data.\n        Consequences:\n            \n        Pros: Retains all cases and avoids the reduction in sample size. Preserves statistical power and can provide\n              more stable parameter estimates.\n            \n            \n              Cons: The choice of imputation method can affect results.\n               Some imputation methods assume that the data are missing at random (MAR), and if this assumption is violated,\n            imputation may introduce bias. Additionally, imputed values may not accurately reflect the true values,\n               leading to potentially incorrect results.  \n                \n                \n      4.Mixed-Model Analysis (Mixed-Effects Model): \n        \n        >Method: Fit a mixed-effects model that accounts for missing data by estimating parameters\n                  based on available data while accommodating individual variability.\n            \n        >Consequences:\n            Pros: Retains all cases, provides unbiased estimates when the missing data are missing at random (MAR),\n            and can account for the correlation structure inherent in repeated measures data.\n            \n         >Cons: More complex to implement, and assumptions about the missing data mechanism (MAR) must be carefully considered.\n             If the MAR assumption is not met, the results may still be biased.\n            \n            \n            ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n     consequences of using different methods to handle missing data?",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "1. Identify the Missing Data Pattern:\n    >Before deciding how to handle missing data, it's essential to understand the pattern of missingness.\n    \n    a. Missing Completely at Random (MCAR): The missing data is unrelated to any observed or unobserved variables.\n    b. Missing at Random (MAR): The missing data is related to observed variables but not to the missing values themselves.\n    c. Missing Not at Random (MNAR): The missing data is related to the missing values themselves.\n    \n  2. Consider Your Sample Size and Data:\n    Assess the extent of missing data. If you have very few missing values or if the missing values are negligible\n    \n    3. Methods to Handle Missing Data:\n      a. Listwise Deletion:\n         - Remove cases with missing data from the analysis.\n         - Pros:\n         - Simple and straightforward.\n         - Preserves complete cases.\n         - Cons:\n         - Reduces sample size, potentially reducing statistical power.\n         - May introduce bias if missing data is not MCAR.  \n            \n       b. Pairwise Deletion:\n          - Include cases with missing data for variables where data is available and exclude them only\n            for variables with missing data.\n          - Pros:\n          - Retains more data and statistical power compared to listwise deletion.\n          - Cons:\n          - Inconsistent sample sizes across variables can complicate interpretation.\n          - Appropriate only if missing data is MCAR or MAR.\n            \n        c. Imputation Methods:\n        Mean Imputation:\n            - Replace missing values with the mean of the available data.\n            - Pros:\n            - Simple and maintains the sample size.\n            - Cons:\n            - Reduces variance, potentially leading to underestimation of standard errors and \n              overestimation of significance.\n                \n           - Assumes data is MCAR, which may not be the case.\n\n   - Regression Imputation:\n\n        - Predict missing values using regression models based on other observed variables.\n        - Pros:\n        - Can provide more accurate imputations.\n        - Cons:\n        - Relies on accurate specification of the regression model.\n        - May not work well if relationships are complex.\n\n        Multiple Imputation:\n        - Generate multiple datasets with imputed values, incorporating uncertainty about missing data.\n        - Pros:\n        - Provides more accurate estimates and standard errors.\n        - Accounts for the uncertainty in imputation.\n        - Cons:\n        - Complex to implement and may require specialized software.\n        - Requires assumptions about the imputation model.\n\n        4. Consequences of Different Methods:\n            \n        The choice of method should consider the missing data pattern, the amount of missing data,\n           and the assumptions about the data.\n         Using inappropriate methods or ignoring missing data can lead to biased and inaccurate results.\n        \n        Listwise deletion can reduce statistical power.\n        \n        Imputation methods may introduce bias if assumptions are violated or if relationships between \n          variables are not well-understood.\n        Multiple imputation is often considered the gold standard but is more complex to implement.    \n        \n        \n            ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n     an example of a situation where a post-hoc test might be necessary.",
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": "1.Tukey's Honestly Significant Difference (Tukey's HSD):\n    When to use: Tukey's HSD is a widely used and conservative post-hoc test suitable for equal group sizes.\n    It's appropriate when you want to compare all possible pairs of group means.\n    \n    Example: In a medical study, you have three different drug treatments,\n    and you want to determine which pairs of treatments have significantly\n    different effects on patients' blood pressure.\n    \n2.Bonferroni Correction:\n    When to use: Bonferroni correction is a stringent method used when you want to control the familywise error rate.\n    It's appropriate when you're conducting multiple pairwise comparisons and want to reduce the risk of \n    Type I errors (false positives).\n    \n    Example: In a marketing study, you have five different advertising strategies,\n    and you want to know which pairs of strategies result in significantly different sales.\n    You use Bonferroni correction to avoid making too many false claims of significance.\n    \n3.Scheffé's Method:\n     When to use: Scheffé's method is a more flexible but less powerful post-hoc test suitable for unequal \n     group sizes and complex study designs. It's used when you have specific research questions that cannot\n     be adequately addressed by other post-hoc tests.\n    \n    Example: In an educational study, you have three groups of students with varying levels of prior knowledge,\n      and you want to determine if the effect of a teaching method differs significantly between these groups.\n        \n4.Dunnett's Test:\n     When to use: Dunnett's test is used when you have a control group and several treatment groups,\n      and you want to compare each treatment group with the control group.\n        \n     Example: In a clinical trial, you have a control group receiving a placebo and multiple experimental\n         groups receiving different drug treatments. You want to determine if any of the experimental groups \n          have significantly different outcomes compared to the control group.\n            \n    ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\nto determine if there are any significant differences between the mean weight loss of the three diets.\nReport the F-statistic and p-value, and interpret the results.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import scipy.stats as stats\n\n\ndiet_A = [4.5, 3.2, 2.8, 3.9, 5.1, 4.7, 4.3, 3.5, 2.6, 4.0, 3.3, 4.2, 4.8, 3.7, 3.1, 4.4, 4.9, 3.8, 3.0, 3.6, 3.4, 4.6, 4.1, 3.3, 5.0]\ndiet_B = [2.0, 1.5, 1.8, 2.7, 2.2, 2.9, 2.4, 2.1, 1.7, 2.3, 2.6, 2.8, 1.9, 2.5, 2.2, 2.0, 2.3, 1.8, 1.6, 2.4, 2.7, 2.1, 2.5, 2.6, 1.6]\ndiet_C = [0.5, 0.7, 0.6, 0.9, 0.8, 0.4, 0.3, 0.6, 0.7, 0.5, 0.8, 0.4, 0.6, 0.9, 0.7, 0.5, 0.3, 0.6, 0.4, 0.5, 0.7, 0.8, 0.6, 0.4, 0.9]\n\n\nf_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n\n\nalpha = 0.05  \n\nprint(\"F-statistic:\", f_statistic)\nprint(\"p-value:\", p_value)\n\nif p_value < alpha:\n    print(\"The p-value is less than the significance level (alpha). Reject the null hypothesis.\")\n    print(\"There is sufficient evidence to conclude that there are significant differences between the mean weight loss of the three diets.\")\nelse:\n    print(\"The p-value is greater than or equal to alpha. Fail to reject the null hypothesis.\")\n    print(\"There is insufficient evidence to conclude that there are significant differences between the mean weight loss of the three diets.\")\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "text": "F-statistic: 284.1626361454677\np-value: 6.816269119215947e-35\nThe p-value is less than the significance level (alpha). Reject the null hypothesis.\nThere is sufficient evidence to conclude that there are significant differences between the mean weight loss of the three diets.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Q10. A company wants to know if there are any significant differences in the average time it takes to\ncomplete a task using three different software programs: Program A, Program B, and Program C. They\nrandomly assign 30 employees to one of the programs and record the time it takes each employee to\ncomplete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\ninteraction effects between the software programs and employee experience level (novice vs.\nexperienced). Report the F-statistics and p-values, and interpret the results.\n   ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport scipy.stats as stats\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\n\n\nnp.random.seed(0)\n\n\ndata = pd.DataFrame({\n    'Software': np.random.choice(['A', 'B', 'C'], size=30),\n    'Experience': np.random.choice(['Novice', 'Experienced'], size=30),\n    'Time': np.random.normal(loc=10, scale=2, size=30)  \n})\n\n\nformula = 'Time ~ Software + Experience + Software:Experience'\nmodel = ols(formula, data=data).fit()\nanova_table = sm.stats.anova_lm(model, typ=2)\n\n\nalpha = 0.05  \n\nprint(anova_table)\n\nmain_effect_software = anova_table.loc['Software', 'F']\nmain_effect_experience = anova_table.loc['Experience', 'F']\ninteraction_effect = anova_table.loc['Software:Experience', 'F']\n\np_value_software = anova_table.loc['Software', 'PR(>F)']\np_value_experience = anova_table.loc['Experience', 'PR(>F)']\np_value_interaction = anova_table.loc['Software:Experience', 'PR(>F)']\n\nprint(f\"Main Effect (Software) - F-statistic: {main_effect_software}, p-value: {p_value_software}\")\nprint(f\"Main Effect (Experience) - F-statistic: {main_effect_experience}, p-value: {p_value_experience}\")\nprint(f\"Interaction Effect - F-statistic: {interaction_effect}, p-value: {p_value_interaction}\")\n\nif p_value_software < alpha:\n    print(\"There is a significant main effect of software programs on task completion time.\")\nelse:\n    print(\"There is no significant main effect of software programs on task completion time.\")\n\nif p_value_experience < alpha:\n    print(\"There is a significant main effect of employee experience on task completion time.\")\nelse:\n    print(\"There is no significant main effect of employee experience on task completion time.\")\n\nif p_value_interaction < alpha:\n    print(\"There is a significant interaction effect between software programs and employee experience.\")\nelse:\n    print(\"There is no significant interaction effect between software programs and employee experience.\")\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "text": "                        sum_sq    df         F    PR(>F)\nSoftware             11.141545   2.0  2.113814  0.142706\nExperience            2.102143   1.0  0.797652  0.380665\nSoftware:Experience   6.013261   2.0  1.140857  0.336272\nResidual             63.249921  24.0       NaN       NaN\nMain Effect (Software) - F-statistic: 2.113813603355667, p-value: 0.14270606204559508\nMain Effect (Experience) - F-statistic: 0.7976521470239053, p-value: 0.38066469830683636\nInteraction Effect - F-statistic: 1.1408571995203571, p-value: 0.33627191875552603\nThere is no significant main effect of software programs on task completion time.\nThere is no significant main effect of employee experience on task completion time.\nThere is no significant interaction effect between software programs and employee experience.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Q11. An educational researcher is interested in whether a new teaching method improves student test\nscores. They randomly assign 100 students to either the control group (traditional teaching method) or the\nexperimental group (new teaching method) and administer a test at the end of the semester. Conduct a\ntwo-sample t-test using Python to determine if there are any significant differences in test scores\nbetween the two groups. If the results are significant, follow up with a post-hoc test to determine which\ngroup(s) differ significantly from each other.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport scipy.stats as stats\n\nnp.random.seed(0)\n\ncontrol_group_scores = np.random.normal(loc=70, scale=10, size=50)\n\n\nexperimental_group_scores = np.random.normal(loc=75, scale=10, size=50)\n\n\nt_statistic, p_value = stats.ttest_ind(control_group_scores, experimental_group_scores)\n\nalpha = 0.05  \n\nprint(\"T-statistic:\", t_statistic)\nprint(\"p-value:\", p_value)\n\nif p_value < alpha:\n    print(\"The p-value is less than the significance level (alpha). Reject the null hypothesis.\")\n    print(\"There is sufficient evidence to conclude that there are significant differences in test scores between the two groups.\")\nelse:\n    print(\"The p-value is greater than or equal to alpha. Fail to reject the null hypothesis.\")\n    print(\"There is insufficient evidence to conclude that there are significant differences in test scores between the two groups.\")\n\nif p_value < alpha:\n    mean_control = np.mean(control_group_scores)\n    mean_experimental = np.mean(experimental_group_scores)\n    \n    if mean_control > mean_experimental:\n        print(\"The control group has a significantly higher mean test score.\")\n    elif mean_control < mean_experimental:\n        print(\"The experimental group has a significantly higher mean test score.\")\n    else:\n        print(\"There is no significant difference in mean test scores between the two groups.\")\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "text": "T-statistic: -1.6677351961320235\np-value: 0.09856078338184605\nThe p-value is greater than or equal to alpha. Fail to reject the null hypothesis.\nThere is insufficient evidence to conclude that there are significant differences in test scores between the two groups.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\nretail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\non those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n\nsignificant differences in sales between the three stores. If the results are significant, follow up with a post-\nhoc test to determine which store(s) differ significantly from each other.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport scipy.stats as stats\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd\n\nnp.random.seed(0)\n\ndata = pd.DataFrame({\n    'Store': np.random.choice(['A', 'B', 'C'], size=90),  \n    'Sales': np.random.randint(1000, 5000, size=90)  \n})\n\n\nf_statistic, p_value = stats.f_oneway(\n    data[data['Store'] == 'A']['Sales'],\n    data[data['Store'] == 'B']['Sales'],\n    data[data['Store'] == 'C']['Sales']\n)\n\n\nalpha = 0.05 \n\nprint(\"One-way ANOVA - F-statistic:\", f_statistic)\nprint(\"p-value:\", p_value)\n\nif p_value < alpha:\n    print(\"The p-value is less than the significance level (alpha). Reject the null hypothesis.\")\n    print(\"There is sufficient evidence to conclude that there are significant differences in daily sales between the three stores.\")\nelse:\n    print(\"The p-value is greater than or equal to alpha. Fail to reject the null hypothesis.\")\n    print(\"There is insufficient evidence to conclude that there are significant differences in daily sales between the three stores.\")\n\n\nif p_value < alpha:\n    posthoc = pairwise_tukeyhsd(data['Sales'], data['Store'], alpha=0.05)\n    print(\"\\nTukey's HSD Post-Hoc Test:\")\n    print(posthoc)\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "text": "One-way ANOVA - F-statistic: 2.1487846682841165\np-value: 0.12277547587202084\nThe p-value is greater than or equal to alpha. Fail to reject the null hypothesis.\nThere is insufficient evidence to conclude that there are significant differences in daily sales between the three stores.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}